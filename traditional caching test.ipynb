{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tavish/miniconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, GRU, Dense\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import scale, StandardScaler, RobustScaler\n",
    "from collections import OrderedDict, defaultdict\n",
    "plt.rcParams['figure.figsize'] = [10, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of csv are 145063 x 804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow down dataset to 75k least popular contents\n",
    "df = pd.read_csv('wikipedia/web-traffic-time-series-forecasting/train_2.csv', usecols=[1])\n",
    "df.fillna(0, inplace=True) # fill missing vals with 0\n",
    "df.sort_values(by=[df.columns[0]], ascending=False, inplace=True)\n",
    "df = df[70000:]\n",
    "ixs = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Caching Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Least Recently Used Cache Policy\"\"\"\n",
    "class LruContentStore():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.store = OrderedDict()\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "\n",
    "    def add(self, item):\n",
    "        if self.size:\n",
    "            if(len(self.store) == self.size):\n",
    "                self.store.popitem(last=False)\n",
    "            self.store[item] = item\n",
    "\n",
    "    def get(self, item):\n",
    "        try:\n",
    "            cached_item = self.store.pop(item)\n",
    "            self.store[item] = cached_item\n",
    "            return cached_item\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Least Frequently Used Cache Policy\"\"\"\n",
    "class LfuContentStore():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.store = {} # {'name', [item, freq]}\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def add(self, item):\n",
    "        if self.size:\n",
    "            if len(self.store) == self.size:\n",
    "                min_key = None\n",
    "                min_freq = None\n",
    "                for key in self.store.keys():\n",
    "                    if min_freq == None or self.store[key][1] < min_freq:\n",
    "                        min_freq = self.store[key][1]\n",
    "                        min_key = key\n",
    "                self.store.pop(min_key)\n",
    "            self.store[item] = [item, 1]\n",
    "\n",
    "    def get(self, item):\n",
    "        try:\n",
    "            cached_item = self.store[item][0]\n",
    "            self.store[item][1] += 1\n",
    "            return cached_item\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Random Cache Policy\"\"\"\n",
    "class RandomContentStore():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.store = {}\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "\n",
    "    def add(self, item):\n",
    "        if self.size:\n",
    "            if len(self.store) == self.size:\n",
    "                self.store.pop(np.random.choice(list(self.store.keys())))\n",
    "            self.store[item] = item\n",
    "    \n",
    "    def get(self, item):\n",
    "        try:\n",
    "            return self.store[item]\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init content stores\n",
    "cache_size = int(0.01 * 75000)\n",
    "lru = LruContentStore(cache_size)\n",
    "lfu  = LfuContentStore(cache_size)\n",
    "rand = RandomContentStore(cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(123)\n",
    "\n",
    "for i in range(50):\n",
    "    df = pd.read_csv('wikipedia/web-traffic-time-series-forecasting/train_2.csv', usecols=[703 + i])\n",
    "    df = df.loc[ixs]\n",
    "    df.fillna(0, inplace=True)\n",
    "    arr = df.values\n",
    "    weights = arr.flatten()\n",
    "    weights = weights/sum(weights)\n",
    "    for j in range(500000):\n",
    "        c = np.random.choice(ixs, 1, p=weights)[0]\n",
    "        if lru.get(c) == None:\n",
    "            lru.add(c)\n",
    "            lru.misses += 1\n",
    "        else:\n",
    "            lru.hits += 1\n",
    "        if lfu.get(c) == None:\n",
    "            lfu.add(c)\n",
    "            lfu.misses += 1\n",
    "        else:\n",
    "            lfu.hits += 1\n",
    "        if rand.get(c) == None:\n",
    "            rand.add(c)\n",
    "            rand.misses += 1\n",
    "        else:\n",
    "            rand.hits += 1\n",
    "        if(j % 100000 == 0):\n",
    "            print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
